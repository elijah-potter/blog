# Bypassing Hallucinations in LLMs

![My bike broke down. Luckily, I had my camera](/images/bike_sidewalk.webp)

Before I get too deep, I just want to get it out of the way: OpenAI's o3 model is impressive.
With its tool use and web search capabilities, it can do a lot more than most offerings out there.

That said, although I've found it to be quite a capable coder, I still don't trust it with anything important.
Once or twice, I've instructed it to outline a React component, only to rewrite most of it myself. 

I also don't trust its factual accuracy at all.
After hallucinating a campground and several entire web APIs, I can't quite believe anything it says. Not that I've trusted any model that came before.

That said, there is one thing it is incredibly useful for: __finding canonical documentation for complex subjects.__

I've found the greatest success, personally and professionally, when I am working with the most concrete and original source of information available.
When working with the web, the most canonical source is the W3C spec.
When working with compilers, it's The Dragon Book. 
When researching the ins and outs of GNU/Linux systems, it's the `man` page.

This can't be a novel concept.
You (the reader) must see things the same way I do.
Even LinkedIn seems to agree that base-truth documentation is where we should be getting our information. 

I've always wondered: if the W3C spec is the best place to find information about the web, why isn't it the first result on Google?
Why, after all these years, is W3Schools _still the first result 90% of the time?_

I use o3 to find canonical sources of information.

I was recently looking to improve the dynamic range in my camera, but do so before my post-processing step. By improving dynamic range in-camera, I can avoid the pitfalls of certain kinds of compression. I asked o3: "find me the canonical guide for improving dynamic range on my D7100 from the most authoritative source." 

I learnt more from the resulting guide (which was hosted on the Nikon website, NOT ChatGPT) than the last three years of shooting, combined. 
